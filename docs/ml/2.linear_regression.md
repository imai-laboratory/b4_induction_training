---
layout: default
title: 2.線形回帰
parent: 機械学習
nav_order: 2
---

# 2.線形回帰

**回帰（Regression）とは?**

以下のような問題設定の下で，変数の推定/予測を行うタスクを「回帰(Regression)」といいます．

> 確率変数$$X \in \mathbb{R}^{d}, Y \in \mathbb{R}$$の実現値からなる$$n$$コのデータサンプル：
>
> $$
>   \mathcal{D} := \left\{ \left( \begin{array}{c} {\bf x}_1 \\ y_1 \end{array} \right), \dots, \left( \begin{array}{c} {\bf x}_n \\ y_n \end{array} \right) \right\} 
> $$
> 
>
> を用いて、$$X$$の値から$$Y$$の値を推定（予測）するモデル：
>
> $$
> f: X \in \mathbb{R}^{d} \mapsto Y \in \mathbb{R}
> $$
> 
>
> を作りたい。

回帰問題は，機械学習における最も基本的なタスクであり，その応用先が広いことから様々なモデル・手法が提案されています．また変数の呼び方は分野によって様々で，$$Y$$は「被説明変数・応答変数・目的変数」，$$X$$は「説明変数・予測変数・独立変数」と呼ばれます．


<br>

**線形回帰モデル**

また，回帰問題において「関数$$f$$が多項式」


1. 線形モデル(Linear Model, LM)
  - 定義
    - 誤差項$$u$$が正規分布に従うと仮定
  - 一般式
    - $$Y = XB + U$$
  - 応用例
    - 回帰分析(t検定，F検定)
    - 分散分析(ANOVA)
2. 一般化線形モデル(Generalized Linear Model, GLM)
  - 定義
    - 誤差項$u$が一般の分布に従うと仮定
  - 一般式
    - $$g(Y) = XB + U$$
  - 応用例
    - ロジスティック回帰
    - ポアソン回帰



**今回のシナリオ**

今回は，ボストン市の住宅価格(TARGET)を目的変数にして線形回帰モデル$$f$$を作ります.関数$f$は6次元ベクトル$${\bf x} \in \mathbb{R}^{6}$$から実数値$$y \in \mathbb{R}$$への写像を6元多項式で表しています.$$u$$は関数$$f$$では表現できなかった部分を補正する誤差項です．

$$
y = f({\bf x}) + u = f(x_1, \dots,  x_6) + u
$$

具体的には，以下のデータを使います．

- 目的変数 (1コ)
  - $$y~ ~ $$ : TARGET - 住宅価格の中央値（単位: 千ドル）
- 説明変数 (6コ)
  - $$x_1$$ : RM - 住居の平均部屋数
  - $$x_2$$ : DIS - 5つのボストン市の雇用施設からの重み付き距離
  - $$x_3$$ : INDUS - 非小売業の土地割合（単位: ％）
  - $$x_4$$ : AGE - 1940年より前に建てられた物件割合（単位: ％）
  - $$x_5$$ : LSTAT - 低所得労働者の割合（単位: ％）
  - $$x_6$$ : CRIM - 人口あたり犯罪発生率（単位: ％）
- 誤差項　
  - $$u$$ ： 平均0の正規分布に従うと仮定．

$$
\begin{align}
y = \beta_0 + \beta_1 x_1 + \cdots + \beta_6 x_6 + u, ~~~
u \sim \mathcal{N}(0, \sigma^2)
\end{align}
$$



**Pythonによるサンプルコード**

- [[回帰問題] Bostonデータ + 線形回帰モデル]({{ site.url }}/docs/ml/boston_LinearRegression.html)
